

ALPHA STAR PAPER Notes
======================================================================================


The policy of AlphaStar is a function πθ(at | st,z) that maps all previous
observations and actions st = o1:t, a1:t − 1 (defined in Extended Data Tables 1, 2) 

observation 1 - t AND acton 1 - (t - 1)

and z (representing strategy statistics) to a probability distribution
over actions at for the current step. πθ is implemented as a deep neural
network with the following structure

* The policy function itself, is a neural network.



The observations ot are encoded into vector representations,
combined, and processed by a deep LSTM9, which maintains
memory between steps.


PYSC2 Notes
======================================================================================

/c/Users/Ryan/AppData/Local/Programs/Python/Python37-32/Lib/site-packages/s2clientprotocol

python -m pysc2.bin.agent --map Simple64


-- Rendering --

Victor's approach:

Concept: Write directly to the GPU (skip canvas and use open GL as done in three js)

Instead of calculating the pixel data directly into a grid map of pixel values, give the gpu coordinates for various shapes and let it do the pixel calculations